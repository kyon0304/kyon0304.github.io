<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on kyon's wonderland with ❤️</title><link>https://kyon.life/post/</link><description>Recent content in Posts on kyon's wonderland with ❤️</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 01 Sep 2021 14:39:48 +0800</lastBuildDate><atom:link href="https://kyon.life/post/index.xml" rel="self" type="application/rss+xml"/><item><title>操作系统导论学习笔记（三）</title><link>https://kyon.life/post/ostep-3/</link><pubDate>Wed, 01 Sep 2021 14:39:48 +0800</pubDate><guid>https://kyon.life/post/ostep-3/</guid><description>只有少量的物理 CPU，操作系统如何提供有几乎无限 CPU 可用的假象？
操作系统通过虚拟化(Virutalization) CPU 来提供这种假象。通过让每个程序只运行一个时间片，然后切换到其他进程，操作系统提供了存在多个虚拟 CPU 的假象。这就是时分共享(time sharing) CPU 共享技术。
潜在的开销就是性能降低，因为如果 CPU 必须共享，每个进程的运行就会变慢。
要实现 CPU 的虚拟化，操作系统需要提供底层 机制（mechanism） 和高层 策略（policy） 的支持：
机制是一些低级方法或协议，比如上下文切换（context switch），让操作系统可以停止运行当前程序，并在给定的 CPU 上运行另一个程序。 策略是操作系统作出某种决定的算法，比如调度策略（scheduling policy）决定当前 CPU 运行一组待运行程序中的哪一个。 分离机制和策略：机制为 how 提供答案，策略为 which 提供答案，将两者分开可以轻松地替换策略，而不必重新考虑机制。这是一种通用的软件设计原则：模块化。
关键问题：如何高效、可控地虚拟化 CPU
操作系统必须以高性能的方式虚拟化 CPU，同时保持对系统的控制。为此，操作系统会巧妙地利用硬件的支持。
受限的直接执行 基本技巧：受限的直接执行 LDE Limited Direct Execution
「直接执行」是指程序直接运行在 CPU 上
「受限」的体现之一，是 CPU 执行模式区分「用户模式 user mode」 和 「内核模式 kernel mode」，用户模式下，程序执行是受限制的，比如不能执行特权操作的（比如访问磁盘 I/O）。
LDE 协议的具体实现方式：
操作系统启动时，内核使用特权指令设置陷阱表 (trap table)，告知硬件接收到特定指令时，到哪里寻找需要执行的程序。 用户程序运行在用户模式下，发出系统调用后，硬件检测到变化，保存当前程序的状态（比如寄存器入栈），转为内核模式，查询陷阱表，然后跳转到对应的内核程序处执行。内核执行完程序后，调用返回用户模式指令，硬件恢复寄存器，转为用户模式，回到应用程序中继续执行。 系统调用类似过程调用，但隐藏在系统接口里的实现，是著名的陷阱指令。为了仔细遵循与内核一致的调用约定（例如将参数放在知名位置），库函数的系统调用部分是用汇编语言手动实现的。
LDE 协议的两阶段实现时间线</description></item><item><title>操作系统导论学习笔记（二）</title><link>https://kyon.life/post/ostep-2/</link><pubDate>Wed, 01 Sep 2021 13:46:35 +0800</pubDate><guid>https://kyon.life/post/ostep-2/</guid><description>进程 操作系统为正在运行的程序提供的抽象，就是进程。
操作系统也是一种应用程序，会使用数据结构保存进程相关的信息。比如保存正在运行的进程的一些附加信息，保存就绪进程列表，跟踪阻塞进程的信息，以便在合适的时机进行唤醒。进程列表这种数据结构，有时也会被称为 程序控制块 PCB Program Control Block
在任何时刻，都可以清点进程在读取和修改什么内容，机器的哪部分会对进程造成影响，我们称之为进程的机器状态（machine state）
机器状态包括：
内存：程序执行的指令和读取及修改的数据，进程可访问的内存称为进程的地址空间 通用寄存器 一些特殊寄存器 PC 指针：程序正在执行的指令 栈指针 stack pointer，帧指针 frame pointer 用于管理函数参数栈、局部变量和返回地址 I/O 信息： 程序访问的持久化存储设备 现代系统进程都会提供的 API
创建：程序变成进程的过程 销毁：如果程序不肯自己退出，操作系统提供了接口让用户结束进程 等待：有时等待进程停止运行是有用的 其他控制：除等待和销毁外的其他控制接口，比如暂停执行和恢复执行 状态：查看进程状态 操作系统创建进程
从磁盘加载代码和静态数据（比如初始化变量）到内存中 尽早加载 eagerly load 惰性加载 lazily load 只加载执行到的片段，需要内存分页和交换机制支持 分配内存，提供给程序的运行时栈使用，也可能会使用参数（argc, argv）初始化栈 也可能会给程序分配堆内存 其他初始化任务，特别是 I/O 相关的 在 Unix 中，所有进程都默认有 3 个打开的文件描述符：标准输入、标准输出和错误输出 启动程序：通过跳转到 main() 例程，操作系统将 CPU 的控制权交到新创建的进程中，从而程序开始执行 进程的 3 种状态及相互转换</description></item><item><title>操作系统导论学习笔记（一）</title><link>https://kyon.life/post/ostep-1/</link><pubDate>Tue, 31 Aug 2021 22:45:12 +0800</pubDate><guid>https://kyon.life/post/ostep-1/</guid><description>为了让程序运行变得更容易，操作系统出现了。操作系统完成的事情包括，允许多个程序同时运行、让程序共享内存、让程序能够与设备交互等。操作系统负责确保系统既易于使用又正确高效的运行。操作系统通过虚拟化（virtualization）做到这一点，操作系统将物理资源（如 CPU、内存或磁盘）转换为更通用、更强大且更易于使用的虚拟形式。因此，我们有时将操作系统称为虚拟机(virtual machine)
设计和实现操作系统的目标 提供高性能，尽可能降低操作系统的性能开销 minimize the overhead 在应用程序之间以及操作系统和应用系统之间提供保护 protection 让进程间彼此隔离是实现保护的关键 isolation 保证高可靠性 reliability 能源效率 energy efficiency, 安全性 security, 移动性 mobility 操作系统的 3 个“简单”部分 虚拟化 virtualizing 持久性 persistence 并行 concurrency 虚拟化 virtualizing 虚拟化又分为虚拟化 CPU 和虚拟化内存。
虚拟化 CPU
在硬件的一些帮助下，操作系统负责提供这种假象（illusion），即系统拥有非常多的虚拟CPU的假象。将单个CPU（或其中一小部分）转换为看似无限数量的CPU，从而让许多程序看似同时运行，这就是所谓的虚拟化CPU（virtualizing the CPU）
虚拟化内存
每个进程访问自己的私有虚拟地址空间（virtual address space）（有时称为地址空间，address space），操作系统以某种方式映射到机器的物理内存上。一个正在运行的程序中的内存引用不会影响其他进程（或操作系统本身）的地址空间。对于正在运行的程序，它完全拥有自己的物理内存。但实际情况是，物理内存是由操作系统管理的共享资源。
持久化 persistence 内存 DRAM 中的数据是易失的，如果断电或系统崩溃，内存中的数据都会丢失。因此我们需要硬件和软件支持来持久地存储数据。
硬件以某种输入/输出设备（Input/Output, I/O）的形式出现。
操作系统中管理磁盘的软件通常称为文件系统（file system）。因此它负责以可靠和高效的方式，将用户创建的任何文件（file）存储在系统的磁盘上。
关键问题：如何持久地存储数据
文件系统是操作系统的一部分，负责管理持久的数据。持久性需要哪些技术才能正确地实现？需要哪些机制和策略才能高性能地实现？面对硬件和软件故障，可靠性如何实现？
并行 concurrency 关键问题：如何构建正确的并发程序
如果同一个内存空间中有很多并发执行的线程，如何构建一个正确工作的程序？操作系统需要什么原语？硬件应该提供哪些机制？我们如何利用它们来解决并发问题？
操作系统的简单历史 早期操作系统：只是一些库 引入保护机制：借助硬件的帮助，区分用户模式和内核模式 多道程序 multiprogram: 提高 CPU 执行效率，避免 I/O 处理拖慢 CPU 执行。出现 Unix 摩登时代：出现个人计算机，遗憾的是，对于操作系统来说，个人计算机起初代表了一次巨大的倒退，因为早期的系统忘记了（或从未知道）小型机时代的经验教训。幸运的是，经过一段时间的苦难后，小型计算机操作系统的老功能开始进入台式机。</description></item><item><title>更科学地使用 maven 管理项目版本</title><link>https://kyon.life/post/mvn-bom/</link><pubDate>Fri, 26 Feb 2021 20:21:48 +0800</pubDate><guid>https://kyon.life/post/mvn-bom/</guid><description>假设一个 demo 项目，按功能划分为组件模块和服务模块，组件模块包含 component-a 和 component-b，服务模块包含 service-1 和 service-2。结构如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ╰─demo$ tree -L 4 -P *.xml --dirsfirst . ├── component-bom │ ├── component-container │ │ ├── component-a │ │ │ ├── src │ │ │ └── pom.xml │ │ ├── component-b │ │ │ ├── src │ │ │ └── pom.</description></item><item><title>禁用烦人的网页弹框 Xdg Open</title><link>https://kyon.life/post/xdg-open-tips/</link><pubDate>Tue, 26 Jan 2021 12:14:58 +0800</pubDate><guid>https://kyon.life/post/xdg-open-tips/</guid><description>打开一个网页，它还想打开关联的桌面应用，有时候是合理的，比如 telegram 的 channel 分享链接，通过网页弹框打开 telegram 还蛮方便，可以直接加入 channel，但是另外一些时候（大部分时候），它就跟弹着玩儿似的，也并打不开什么应用，就很烦，所以我们要无情地把它禁用掉：不能惯着！
一个烦人的例子：
烦人的弹出框
因为日常使用浏览器是 chrome，解决方案也是针对 chrome 的。
首先，确定是想要打开什么鬼应用，查看网页源码，在 &amp;lt;head&amp;gt; 标签中找到可疑 script 引用：
1 2 3 &amp;lt;script src=&amp;#34;https://analytics.snssdk.com/meteor.js/v1/1680583551421512/sdk&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;https://res.wx.qq.com/open/js/jweixin-1.3.2.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;https://g.alicdn.com/dingding/dingtalk-jsapi/2.7.13/dingtalk.open.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; 然后，在新窗口中打开这些链接，看看是不是它们打算打开本地应用：
抓到一个
抓到了，这种好像私有协议的东西就很可疑，先记下来，然后接着往后看：
又抓到一个
dingtalk.open.js 里倒是没有发现打开本地应用的代码，可能是兼容性比较好？
好，接下来进行屏蔽就好了，新建一个文件夹（注意，从此处开始，是只针对 chrome 的解决方案）：
1 sudo mkdir -p /etc/opt/chrome/policies/managed/ 新建文件
1 sudo touch /etc/opt/chrome/policies/managed/whitelist.json 把刚刚发现的两个私有协议放进新建的文件中：
1 { &amp;#34;URLWhitelist&amp;#34;: [&amp;#34;wxlocalresource://*&amp;#34;, &amp;#34;bytedance://*&amp;#34;] } 看一下：</description></item><item><title>使用 spring cloud openfeign 的一些小技巧</title><link>https://kyon.life/post/tricks-with-feign/</link><pubDate>Sun, 17 Jan 2021 15:10:12 +0800</pubDate><guid>https://kyon.life/post/tricks-with-feign/</guid><description>spring cloud openfeign（以下简称 feign） 通过一个额外定义的 interface 文件作为接口定义，可以将对外提供的 HTTP 接口转换为 API 接口，提供方和调用方需要共同依赖接口文件，将隐式的依赖关系显性表示出来。而且在这个接口文件上也可以大作文章，比如配置服务发现、接口拦截操作等。
一个最简单的 feign 接口文件 DemoClient.java：
1 2 3 4 5 6 7 8 package com.example.demo; @FeignClient(name=&amp;#34;demo&amp;#34;, url=&amp;#34;http://127.0.0.1:8081/&amp;#34;) public interface DemoClient { @GetMapping(&amp;#34;/hello&amp;#34;) String hello(@RequestParam String name); } name 为全局唯一，是这个 FeignClient 的唯一标识，url 为提供方的接口地址。理论上 FeignClient 文件由接口提供方作为合约文件给到调用方，但是即使提供方未提供，只要提供方暴露了 HTTP 接口，那么调用方就可以通过定义 FeignClient 文件将 HTTP 接口调用转换为 API 调用。
调用方使用 DemoClient 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 package com.</description></item><item><title>第三章 垃圾收集器与内存分配策略</title><link>https://kyon.life/post/java-garbage-collector/</link><pubDate>Mon, 23 Nov 2020 21:53:51 +0800</pubDate><guid>https://kyon.life/post/java-garbage-collector/</guid><description>3.3 垃圾收集算法 分代假说 从如何判定对象消亡的角度，垃圾收集算法可以分为两大类：「引用计数式垃圾收集」和「追踪式垃圾收集」，主流 Java 虚拟机都采用第二种。
分代垃圾收集理论基于三个假设：
弱分代假说：大部分对象都是朝生夕死 强分代假说：活过越多次垃圾回收的对象越不容易被回收 跨代引用假说：跨代引用相对于同代引用来说占比极少 因此应当将内存划分为不同区域，根据对象存活过的回收年龄放到不同区域，适用不同的回收算法，对象间即使存在跨代引用，也是极少数，不需要扫描整个老年代，只需要通过记忆集存储即可。泛泛而论，大部分对象位于新生代，适用标记-复制算法回收，熬过多轮回收的对象位于老年代，适用标记-整理算法。
标记-清除算法 最初始、最基本的追踪式垃圾回收算法，先标记出需要回收的对象，然后清除，相应内存位置变为可用状态。容易产生内存碎片。
标记-复制算法 简称为复制算法，为了解决内存碎片问题，留出一半空间不使用，开始回收内存时，先标记，然后将不可回收对象复制到未使用空间，另外一半空间直接清除。时间效率高，但是浪费一半空间。
基于 IBM 一项研究，新生代对象 98% 都可以在第一次垃圾回收时被回收掉，因此可以降低空间浪费，hotspot 虚拟机中，新生代分为 eden、s0、s1 三个区域，大小比例为 8:1:1 空间浪费由 50% 降低为 10%。新生成对象先进入 eden 区，s0, s1 两个区域总有一个保持未使用状态，假设开始垃圾回收时，s1 未使用，将不可回收对象放入 s1，然后清除 eden 和 s0。如果 s1 不够用，就放入老年代。
标记-整理算法 如果存活对象过多，比如老年队，标记-复制算法的效率就会显而易见降低。而且，如果不想浪费 50% 空间，就必须有另外的担保空间，在 s0 或 s1 区域不够放时接住对象。
在标记-清除算法基础上改进，标记完毕后，不是直接清除可回收对象，而是将存活对象移动到内存区域一端，然后将剩下的区域清除，相当于做了个整理操作。
移动存活对象，垃圾回收过程会复杂，执行效率低，并且需要 stop the world，不移动存活对象，由于内存碎片，内存分配过程会复杂。但是总体而言，还是移动存活对象会使得整个内存使用的吞吐量更高。关注低延迟的 CMS 是基于标记-清除算法，关注总吞吐量的 Parallel Scavenge 是基于标记-整理算法。内存碎片过多时，CMS 会触发一次内存整理。
3.4 Hotspot 虚拟机的算法细节实现 枚举根节点 GC Roots 遍历需要 stop the world，因此要尽可能快，由于 Java 虚拟机主流基本都使用准确式内存管理，即记录了内存中数据类型，因此使用 (Ordinary Object Pointer)OOPMap 数据结构记录对象引用就可以快速拿到所有 GC Roots。</description></item><item><title>Spring 框架缓存故障自动切换</title><link>https://kyon.life/post/dynamic-switch-cache-in-spring/</link><pubDate>Tue, 29 Sep 2020 15:40:36 +0800</pubDate><guid>https://kyon.life/post/dynamic-switch-cache-in-spring/</guid><description>现状 缓存只是提高访问速度，应用本身没有很高的并发访问量，缓存不可用时，数据库也能顶住。但是缓存挂掉以后，Spring CacheManager 默认会抛出异常，方法直接就异常退出了。
目标 缓存不可用时，不影响应用正常运行，不影响接口正常返回。
解决方案 方案一 最直接的方案，Spring 定义的 error handler 默认是抛出异常，覆盖 handler 并 catch 住异常不要抛出就可以不影响正常处理流程。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public class CacheErrorLoggingHandler extends SimpleCacheErrorHandler { private Logger logger = LoggerFactory.getLogger(CacheErrorLoggingHandler.class); private ClientResources clientResources; public void setClientResources(ClientResources clientResources) { this.clientResources = clientResources; } @Override public void handleCacheGetError(RuntimeException exception, Cache cache, Object key) { logger.</description></item><item><title>Philosophy of Software Design 第三章 仅仅能工作的代码是不够的（编程时的战略 vs 战术思维）</title><link>https://kyon.life/post/philosophy-of-software-design-3/</link><pubDate>Mon, 24 Feb 2020 11:45:01 +0800</pubDate><guid>https://kyon.life/post/philosophy-of-software-design-3/</guid><description>好的系统设计最重要的元素之一是完成编程任务时所采取的思考方式。许多组织鼓励使用战术性思维，专注于尽快使功能上线工作。然而，如果想获得好设计，则必须采取战略思维，在简洁的设计和修复问题上投入更多时间。这章讨论了为什么采用战略思维可以获得更好的设计，而且从长远来看，实际上要比战术思维更节省时间。
3.1 战术式编程 大多数程序员采用我称为战术式编程的方式进行软件开发。这种方式中，主要关注点是得到能工作的东西，比如一个新功能或修复一个 bug。第一眼看去，似乎完全合理：还有什么能比写出可以工作的代码更重要呢？然而，战术式编程很明显不能产生一个好的系统设计。
战术式编程的问题在于短视。采用战术式思维编程时，你就会尽快地完成一项任务。可能面临着硬性规定的截止时间。最终，为未来做计划的优先级就会变低。你不会在寻找最好的设计上花费太多时间；你只是想要尽快获得可以工作的代码。你会自我催眠，认为如果可以更快地完成当前任务，那么增加一点复杂度或者混入一两个不和谐因素也没什么问题。
这就是系统如何变复杂的。正如前一章中讨论的那样，复杂性是增量的。并不是某一个特定的问题，而是数十或数百个小问题的积累使得系统变复杂了。如果你采用战术式编程，每一个编程任务都会向这些复杂性做贡献一些问题。每一个问题可能看上去都是为了快速完成当前任务的合理折中。然而，复杂性会迅速积累，尤其是如果每个人都采用战术式编程的话。
不久之后，一些复杂性就会开始导致问题，你将会开始希望当时没有走捷径。但是，你仍会告诉自己，使得下一个功能尽快工作要比反过头来重构已有代码重要得多。长远来看重构可能可以帮得上忙，但是绝对会拖慢当前任务的进度。所以，对于碰到的任何问题，你就会寻找可以解决它的快速补丁，而这又会在将来需要更多的补丁。很快代码就会变成一团糟，但是此时想要清理代码的话将耗费数月的工作。你的日程不可能负担得起这样的延迟，而且修复其中一两个问题看上去也不会有什么效果，所以你会仍旧保持战术式编程。
如果你曾经在一个大型软件项目中工作过很久，我猜你曾经在工作中见过战术式编程并且经历过它带来的问题。一旦你开始采用这种方式，就很难做出改变。
几乎每个软件开发公司都至少有一名把战术式编程发挥到极致的开发人员：战术式飓风。战术式飓风是一名高产的程序员，他地代码产出速度比其他人快得多，但是完全以战术式思维的方式工作。当涉及实现一个快速功能时，没有人可以比战术式飓风更快的完成。在一些公司中，管理层将战术式飓风视为英雄。然而，战术式飓风会留下一系列破坏痕迹。他们很少被将来必须和他写的代码打交道的工程师视为英雄。通常，其他工程师必须清理战术式飓风造成的混乱，这会使得这些工程师（真正的英雄）看上去比战术式飓风的进度更慢。
3.2 战略式编程 成为一个好的系统设计师的第一步是要意识到 仅仅能工作的代码是不够的。 为了完成当前任务而引入不必要的复杂性是不可接受的。更重要的是系统的长期结构。任何系统中的大多数代码都是在已有代码的基础上扩展而来的，所以作为开发者最重要的工作是为那些将来的扩展提供便利。因此，不应当把“可以工作的代码”当作首要目标，尽管你的代码当然必须可以工作。你的首要目标必须是获得好设计，然后也恰好可以工作。这就是 战略式编程。
战略式编程要求有投资的思维。相较于采取最快的方式完成当前项目，你必须投资一些时间提升系统的设计。这些投资短期看会稍微拖慢你的进度，但是长期来看它们会加速你的开发，如图 3.1 所示。
一些投资是主动的。比如，为每个新建的类多花一点时间找到简单的设计是值得的；与其实现蹦到脑子里的第一个主意，不如尝试一些其他的设计并选择其中最简洁的。试着想象一下未来系统可能会向哪些方向改变，并且保证你的设计可以使得这些改变会很容易。编写良好的文档是主动投资的另外一个例子。
其他投资将会是被动的。不管你前期投资了多少，你的设计决定不可避免地会出现错误。随着时间流逝，这些错误会变明显。当你发现了一个设计问题，不要忽略它或仅仅通过打补丁解决；花费一些额外的时间来修复它。如果采用战略式编程，你将会对系统设计持续性地做出小改善。这是战术式编程的反面，那种方式下你会持续性地增加复杂性并在将来引发问题。
3.3 投资多少时间？ 所以，投资的时间正确数量是多少呢？巨大的前期投资，比如尝试设计整个系统，是低效的。这是瀑布式方法，而且我们知道它不奏效。理想的设计倾向于随着你获得系统的经验而一点点地出现。因此，最好的方式是在连续的基础上作出大量的投资。我建议花费大约占开发时间的 10-20% 在前期投资上。这个数量足够小，不会显著影响你的日程安排，但是又足够大，可以随着时间获得明显的收益。因此你最初的项目花费的时间要比纯粹的战术式方式长 10-20%。这个额外的时间会导致更好的软件设计，并且几个月内你就会开始享受这些好处。不久之后，你的开发速度就会比当时以战术式编程的人快至少 10-20% 。到这个时候，你的投资就会变成免费的了：从你过去的投资中的获益将会节省足够多的时间覆盖将来的投资。你将会快速地从初始的投资中恢复。图 3.1 展示了这种现象。
__图 3.1__：开始，战术式编程会比战略式编程进度更快。然而，战术方式下复杂性会更快地积累。随着时间流逝，战略方式进度会更快。注意：这张图只是定性的说明；我不知道任何可以对这个曲线进行精确测量的经验
相反，如果你采用战术式编程，你将会更快地完成第一个项目，但是随着时间流逝，你的开发速度会随着复杂性累积而变慢。你将会很快地将开始节省的时间还回去，而且在这个系统剩下的生命中，你的开发速度会越来越慢。如果你从未在糟糕的代码基础上工作过，和其他有过这种经历的人聊一聊；他们会告诉你糟糕的代码质量至少会拖慢 20% 的开发速度。
3.4 初创企业和时间投资 在一些环境中有着强大的力量反对战略式方式。比如，早期的初创企业有着将他们的早期版本发布出去的巨大压力。在这些公司中，看上去即使是 10-20% 的投资也支付不起。最终，许多初创企业采取了战术方式，在设计上花费的时间很少，清理出现的问题时花费的时间甚至更少。他们用这样的想法将这些行为合理化：如果他们成功了，他们会有足够的钱雇佣更多的工程师来做清理。
如果你在有这种倾向的公司中，你应当已经意识到，一旦代码库变混乱，想要修复基本是不可能的。在这个产品的生命中你可能需要支付很高的研发花费。而且，好（或坏）设计的报应来得非常快，所以，战术方式很可能甚至无法加速你第一个产品的发布。
另外一件需要考虑的事情是，公司成功的最关键的因素之一是它的工程师的质量。降低开发花销的最好的方式是雇佣厉害的工程师：他们的成本不比平庸的工程师多多少，但是他们有着高得多的产出。然而，最好的工程师非常关注好的设计。如果你的代码库一团糟，事情会传出去，你会更难进行招聘。最终，你很可能只能拥有平庸的工程师。这回增加未来的花费，而且很可能会导致系统结构进一步降级。
Facebook 就是一个鼓励战术编程的初创企业的例子。很多年来这家公司的座右铭是“快速行动并打破东西。”刚刚从大学毕业的新入职工程师被鼓励立即深入公司的代码库；工程师在他们入职的第一周就向线上提交代码曾经是很常见的。积极的一面是，Facebook 作为一家给员工赋权的公司而闻名。工程师有着巨大的自由，基本没有什么规则和约束阻碍他们。
Facebook 作为一家公司曾经非常成功，但是它的代码库由于公司的战术方式而遭受了损失；大多数代码都不稳定而且难以理解，基本没有注释和测试，使用时非常痛苦。随着时间流逝，这家公司意识到它的文化是不可持续的。最终，Facebook 把座右铭变为“在坚实的基础架构上快速行动”来鼓励它的工程师在好的设计上投资更多时间。Facebook 是否能成功地清理数年来战术式编程累积地问题还有待观察。
对 Facebook 讲句公道话，我应当指出 Facebook 的代码可能不比初创企业的平均水平差多少。初创企业中战术式编程是家常便饭；Facebook 只是恰好是一个特别明显的例子。
幸运的是，采用战略方式也可能在硅谷中成功。Google 和 VMware 差不多和 Facebook 同时起家，但是这两家公司都拥抱了更战略化的方式。它们都很重视代码的质量和好的设计，而且都基于可信赖的软件系统构建了解决复杂问题的精致的产品。这些公司强烈的工程文化在硅谷变得出名。很少能有别的公司可以在招聘顶级人才中竞争得过它们。
这些例子表明公司可以以任一种方式成功。然而，在关注软件设计并拥有干净代码库的公司工作要有趣得多。
3.5 结论 好的设计不是免费的。你必须持续性的进行投资，这样小的问题就不会积累成大问题。幸运的是，好设计最终会偿付它自己，而且比你认为的要更快。
采用战略方式时从一而终是非常重要的，而且要把投资当作今天要做的事情，而不是明天。当你进入一个紧张的工期，把清理工作推到这个工期结束后会非常具有诱惑性。然而，这是一个滑坡；当前紧张的工期结束后，几乎总是会有另外一个，然后又是另外一个。一旦你开始推迟设计提升，推迟很可能会变为永久的，然后你的文化会滑向战术方式。你等待解决设计问题越久，问题就会变得越大；解决方案会变得越吓人，这又会使得推迟解决变得更容易接受。最有效的方式是每个工程师都为好的设计持续性地做出投资。</description></item><item><title>修改博客主题</title><link>https://kyon.life/post/change-theme/</link><pubDate>Fri, 21 Feb 2020 18:39:03 +0800</pubDate><guid>https://kyon.life/post/change-theme/</guid><description>没有记录的就没有存在过。所以稍微记录一下。其实不是第一次折腾主题了，之前应 邹扒皮 之约，研究过一次的 Jekyll 的 Next 主题，当然是别人 port 到 Hugo 的版本，但是最终放弃了，因为各种细节都很粗糙，我也没有想要改的动力。
这次是昨天看到 kubectl-debug 的作者的 博客，文章宽度更宽一些，超链接样式很可爱，图例也有专门的样式，文章的 meta 信息也不那么抢眼，总之就是撞到我心坎里了吧，然后看了下也是 hugo 主题，之前其实就想换主题来着，一直没找到心仪的，于是决定这次就把现在的主题换掉。
哦对了，新主题是 Hermit。
下面说一说替换主题都做了什么修改。
之前用 even 的时候其实也做了一些定制化，比如分享啊，把目录从文章右侧挪到左边啊，根据文章 front Matter 里的 keyword 加推荐阅读啊，这种小小的修改。之前涉及到样式的修改，是先安装 node 和 yarn，然后在 even 目录里 yarn install/build 这样非常笨地在做，这次在 Hermit 的 ReadMe 里看到只要下载 extended 的 hugo 就可以编译 scss 了，之前要是知道的话能省不少事。
不打算写成教程向的，纯粹随缘记录。
遇到第一个麻烦的事情是，Hermit 的主题颜色只有一种，没有像 even 那样定义成不同主题一键切换，不过总的来说用到的颜色也不多，只是自己用，全局查找替换一下不是什么问题。问题是，要用什么颜色。。这个花了蛮久的，在这个网站上复制粘贴了很多色值，一个个试的，其实底部栏的颜色也不是特别满意，但实在已经试到心焦气燥了，就先这样。
然后是解决目录不显示的问题，even 里是在全局和文章的 front matter 变量两个地方同时控制，并且文章的优先级高一些，hermit 是只能用文章的 front matter 变量。但是我现有的文章都没有显示指定，直接在全局变量设置的，于是想改成和 even 一样的逻辑。但是试来试去，目录就是不出现，后来发现 hermit 的目录有两个地方，一个是文章目录本录，另外一个是文章右下角的目录开关，即使有目录也要先按开关切换以后才会出现，很不爽啊，于是直接改了下目录 css 类，让它直接显示，后面修改是否出现目录的逻辑也就水到渠成了。
想起来，第一个事情应该是修改配置文件，从 exampleSite 里拷贝出来的默认的配置文件是 toml 格式的，但是上次折腾推荐阅读的时候发现，其实对 yaml 的支持度更好，于是那时就换成了 yaml 格式。只是当时比较直愣愣，一行一行手动改的，今天突然想起了应该有 convert 工具啊，hugo 确实有个子命令是 convert，但可惜是转换文章 front matter 格式的，于是上网随便搜了个网站转了下，复制粘贴回来。然后照着之前 even 主题时候的配置增删改查一下。说到这里不得不提一下，even 的配置还是蛮良心的，量大，还有注释。这次修改去掉了不少配置，包括 busuanzi 的 PV/UV 统计，虽然之前一直看一直看，但它总是不变看着也闹心啊。留了一个 GgoogleAnalytics，以后想起来去看看就得了。</description></item></channel></rss>